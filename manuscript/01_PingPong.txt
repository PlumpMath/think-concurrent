
# Warming up: Ping-Pong

The classical "Ping-Pong" example is to concurrency what the infamous "Hello World!" is to sequential programming. It is a minimal system that still exposes some key features of (here concurrent) programs:

  - there's **parallelism**: there is a Ping *and* there is a Pong,

  - there's **interaction**: the Ping talks to the Pong and *vice-versa*,

  - there's **non-determinism**: this will sprinkle with *pain* over the *joy*,

  - there's **no termination**: use your `Ctrl-C` to stop the program.

But still similarly to its sequential welcoming cousin: this is *not* a deeply interesting example, so it's perfect to focus on the *compile-and-run* issues.

Technically-speaking, the system we are going to build consists of two *threads* that exchange and print Ping-Pong messages through *channels*. Here they are! the "big" words have been shouted out.

A> A **system** is composed of **threads** that exchange messages through **channels**.

That pretty much summarizes what *core.async* is all about !

## Version 1: the tireless ping-pong players

But first things first, let us write our first *core.async* example. The namespace specification is the following one.

{crop-start-line=1,crop-end-line=3}
<<[pingpong.clj](code/think-concurrent/src/think_concurrent/pingpong.clj)

The `clojure.core.async` namespace provides is where the main API resides. Since it's in the core it is fairly common to `refer` the main functionalities, especially the cryptic ones such as `>!!` (blocking send) and `<!!` (blocking receive).

Now, the behavior of both our threads can be specified as a single function:

{crop-start-line=5,crop-end-line=10}
<<[pingpong.clj (cont'd)](code/think-concurrent/src/think_concurrent/pingpong.clj)

The first parameter `ch` is intended to be a communication channel on which the thread interact.
The parameter `kind` indicates the message that the thread will emit: either `"Ping ! "` or `"Pong ! "`.

We next enter a loop consisting in indefinitely repeating the following sequence.

1. First, in the expression:

    {lang="clojure"}
        (let [msg (<!! ch)]
          ;; do something with msg
          ...)

    the current thread listens on channel `ch` and *blocks*  until a message `msg` can be received.

2. Then, with:

    {lang="clojure"}
        (print msg) (flush)

    the thread print the message upon reception (note the `flush` for safer -- but not completely safe -- outputs).

3. Finally, with:

    {lang="clojure"}
        (>!! ch kind)

    the thread *blocks* until it can send on channel `ch` its own `kind` of message: the string `"Ping ! "` if we're the *pinger*, and the string `"Pong ! "` if we're the *ponger*.

4.  And finally we `recur` for good.

I> ## Blocking send and receive actions on **synchronous channels**
I> The fundamental characteristic of the send and receive operations of `core.async` is that they are potentially *blocking*. Using the default semantics of *synchronous channels* we have:
I>
I>  - a thread performing a receive action  `(<!! ch)`  (receiving on channel `ch`)  will block until another thread performs a corresponding send action `(>!! ch value)`, i.e. sending some `value` on the *same* channel `ch`,
I>  - and `vice-versa`.

We have now everything we need to create our first complete, although overally useless, *core.async* program.

{crop-start-line=12,crop-end-line=16}
<<[pingpong.clj (cont'd)](code/think-concurrent/src/think_concurrent/pingpong.clj)

1. First we create a synchronous channel using is the `chan` primitive of *core.async*:

    {lang="clojure"}
        (let [ch (chan)]
          ;; ... let's use the channel ch
          ...)

    The channel `ch` can then be used in the body of the `let` for sending (with `>!!`) and receiving (with `<!!`), among other possibilities.

2. We create a *ping* thread to run in parallel with the current thread:

    {lang="clojure"}
        (thread (pingpong ch "Ping! "))
        ;; ... two threads are now running
        ...

    The `thread` primitive is used to spawn a new ... guess what ? ... *thread* of course ! The body of the `thread` primitive is executed in a newly spawned JVM thread, a.k.a. an *heavyweight* thread, and thus runs in parallel with the thread calling the primitive. This also means that the call to `thread` is non-blocking. The library *core.async* can also handle much more *lightweight* threads, which we will discuss at lenght, at large and in depth.. but for now we will contend with the heavy ones.

3. The system is started by sending a first message `"Start!"` to channel `ch`.

    {lang="clojure"}
        (>!! ch "Start! ")

4. The main thread becomes the *pong* part:

    {lang="clojure"}
        (pingpong ch "Pong ! ")

    Since the `pingpong` function involves an infinite loop, our main threads never
    returns.


To actually run the example, we can either:

  - start a `repl`  (using `lein repl`) and type

        => (run-ping-pong)

    at the prompt[^run], or

    [^run]: the `think-concurrent.core` namespace require all the main functions of the examples.

  - directly launch the example with `lein run pingpong`[^ex].

    [^ex]: all the examples can be tried using `lein run` *<example>*  with *<example>* probably as you could guess.

Let's try the second solution:

~~~~~~~~
$ lein run pingpong
--------------------------------------------
Example: pingpong
--------------------------------------------
Start! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! ... and this can continue for some time ...
~~~~~~~~

... at some point I suggest that you hit the `Ctrl-C` key (or reboot on windows[^joke] ?).

[^joke]: people working with computed in the mid-90's may remember such w-bashing jokes with nostalgia.

## Version 2: the gas-guzzlers with a paddle

Not *all* concurrent programs are non-terminating, but let's say that if non-termination is a show-stopper for sequential programs, it is a *feature* of many concurrent programs. In fact, ensuring the termination of a concurrent program can easily become non-trivial. As an illustration, we
will modify the Ping-Pong example so that it predictibly terminates. One simple way would be to let the program run for a given amount of "real" time, e.g. 2 seconds. We could spawn two parallel threads and then call `(Thread/sleep 2000)` in the main thread. But the termination is here quite impredictable (it runs for *about* 2 seconds) and abrupt: the terminating thread will kill all the threads it's spawned (think `kill -9` !).  One idea to make a thread self-terminating predictably is to provide it with some fuel, and force the thread termination when it's exhausted (I hope you're not!).

{crop-start-line=18,crop-end-line=24}
<<[pingpong.clj (cont'd)](code/think-concurrent/src/think_concurrent/pingpong.clj)

The *runner* is modified accordingly.

{crop-start-line=26,crop-end-line=33}
<<[pingpong.clj (cont'd)](code/think-concurrent/src/think_concurrent/pingpong.clj)

We notice that the value returned by the `thread` primitive is exploited in the example,
 so that the thread can be *joined* upon termination.

I> ## The `thread` primitive and joining
I> An expression of the form:
I>
I> {lang="clojure"}
I>     (let [join (thread ...body...)]
I>        ;; ... the thread is joinable on channel join
I>        ...
I>        (<!! join)  ;; this will block until the thread terminates
I>        ...)
I>
I> creates as a side-effect a system-level thread running the *body* expression, and
I> returns immediately with a *read-only* synchronous channel `join` that can be used
I> to *join* the thread, i.e. wait for its *termination*.

Let's start the system at the repl this time:

~~~~~~~~
$ lein repl
nREPL server started on port 46154 on host 127.0.0.1 - nrepl://127.0.0.1:46154
REPL-y 0.3.7, nREPL 0.2.12
Clojure 1.8.0
OpenJDK 64-Bit Server VM 1.8.0_121-8u121-b13-3-b13

   ... etc ...

=> (run-pingpong-fuel 10)
Start! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Joined!
nil
=> (run-pingpong-fuel 5)
Start! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Joined!
nil
~~~~~~~~

This is what you may obtain if you're lucky enough (which means: most of the time!).
If you're unlucky (which means: rarely enough!) you could see something more like this:

~~~~~~~~
=> (run-pingpong-fuel 10)
Start! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong! Ping! Pong!
~~~~~~~~

Here, the system does *not* terminate because the *pinger* blocks at some point and the join on channel `j` in fact never occurs (and in this case you have type hit `Ctrl-C`).  What happens is that the *ponger* thread sees its fuel exhausted too soon. Look at the trace: the first message is `Pong!` and not `Ping!` as in the other cases. This may occur because the first send `(>!! ch "Start! ")` is *non-deterministic*. It will either awake the *pinger*  or the *ponger* (and the `(Thread/sleep 100)` is here to make sure this *actually* happens). If the *ponger* starts, then it's last action will be to send it's `fuel`-th message. At the other end the *pinger* will receive the message for the `fuel`-th time.  But then there is no one to synchronize with since the *ponger* terminated. When the *pinger* is started first, we reach a situation where only the *ponger* remains blocked. But this is not a problem since we join the *pinger* in the runner.

I told you: *non-determinism* sometimes bites, and when it does ... that hurts !

Q> ## Non-determinism ?
Q> A sequential program is most of the time *deterministic*: provided we provide
Q> the same input, two distinct executions of the same program will produce the same result.
Q> It is even a stronger requirement for the *pure functional* parts.
Q> A concurrent program is often (but not always!) *non-deterministic*: provided with the
Q> same input, two distinct executions can produce very different outcomes.
Q> Is this a feature we should desire or fear? I would say both. On the one hand, *non-determinism*
Q> is often the price to pay for the tremendous gain of performances offered by
Q> concurrent programs on parallel hardware. On the other hand, this is a major source
Q> of bugs that are extremely difficult to track-down, and whose effects can be
Q> disastrous. Frameworks such as `core.async` offer ways to control *non-determinism*
Q> thanks to powerfull abstractions. But we shouldn't be too naive, this is a
Q> difficult issue and there's no [silver bullet](https://en.wikipedia.org/wiki/No_Silver_Bullet).

So, how do we solve this issue ? One way that preserves *non-determinism* (in many situations this is what we want!) is to give an extra gallon of fuel for the *ponger*. If the *pinger* terminates first it will be blocked before exhaustion anyway, and the extra fuel will allow the *pinger* to terminate properly.

X> ## Exercise: the deterministic Ping-Pong
X> Another, more robust solution would be to modify the program so that the initialisation becomes deterministic.
X> An idea is to split the `pingpong-fuel` definition in two, and only allows e.g. the *pinger* to start first.

## Interlude: concurrent programming metaphors

There exist many ways to design and write concurrent and parallel programs. There are two main metaphors:

  1. the **shared memory metaphor** is based on concurrent reads/writes on shared variables, most of the time using locking mechanisms to prevent issues. This is clearly the most common approach to concurrent programming, but it is low-level and error-prone. Note that this is really a metaphor in that modern processors have multiple cores with non-shared caches that involves queuing, hence the full sharing metaphor is just a view of the mind.

  2. the **message-passing** metaphor is a higher-level view inspired by the physical world. In this metaphor messages are exchanged among entities by means of communication mediums.

The *clojure* case is interesting. At the basis you find the JVM and its very advanced support for shared memory interactions. But it is (I think) an accepted knowledge that programming even at the level of java threads using object monitors, synchronized blocks and methods, volatile variables and compare-and-swap operations on atomic objects is at the very best *error-prone*. The language *clojure*, beyond being a lisp of the JVM[^jlisps], provides many (perhaps too many ?) abstractions for concurrency. First, it promotes (and provides) immutable datastructures and pure functions, which are parallelism-friendly (as long as your GC is parallel and efficient).  But in order to cope with the (unavoidable) hardness of concurrent programming, it also provides many abstraction: software transactional memory (STM), transients, ..., and of course and before all *core.async* which is, in my opinion, the better tool in this rich toolset.

[^jlisps]: While I *do* enjoy programming in Clojure, and greatly appreciate the fact that it is perhaps the most popular Lisp ever, there are other interesting Lisps for the JVM, especially (Kaffe)[] for the Schemers and (ABCL)[] for the Common Lispers.

To speak about *core.async*, it is clearly a member of the *message-passing* family. In this family you will mainly find the actor-based languages and the channel-oriented languages based on Tony Hoare's *communicating sequential processes* (CSP). I think *core.async* could be called a **Channel Oriented Programming** framework (COP ? really ?).  So in clojure you get the best of both world!

I> ## Channels: what else ?
I> *core.async* is by no means the first language adopting a *channel-first* view of concurrency.
I> The most famous example is the *Communicating Sequential Processes* (CSP) by *C.A.R. Hoare*.
I> In a seminal scientific paper (1978) the syntax and informal semantics of a programming formalism
I> for concurrency is proposed, that of course involves processes and channels.
I> This will ultimately evolve to both a *theory*  (the [CSP formalism](http://www.usingcsp.com), which is
I> related although distinct) and a real programming language, perhaps slightly ahead of its time: [OCCAM](http://www.wotug.org/occam).
I> Note, however, that channel references cannot be transmitted in CSP/OCCAM  (at least not in
I> the original versions). Robin Milner's [Pi-calculus](https://en.wikipedia.org/wiki/Π-calculus)
I> appears to me as in fact closer to the *core.async* 
I> semantics (as long as we restrict to synchronous channels). There is also a long tradition
I> of channel-based programming language originally from the Bell labs:  beginning with *Newsqueak*
I> , continuing with *Alef* in Plan 9 and then *Limbo* in Inferno. This [list](https://swtch.com/~rsc/thread)
I> ends with the langage [Go](http://golang.org) that is now quite popular.
I> However, *core.async* is *way* cooler! (there's a Lisp below).


## Process diagrams

The two main abstractions provided by *core.async* are the *processes* (either JVM threads or so-called *go processes*) and then *channels* they use to communicate with each other. At one point in time, it is possible to depict the structure of a *core.async* system as a network structure with:

  - nodes representing processes

  - directed arrows for established communication channels

  - arrow heads for pending receive operations

  - arrow tails for pending send operations.

The fact that for example the pinger process is blocking while sending its message can be
depicted as follows:

![Blocking send](images/pinger-sender.svg)

When the pinger is sending and the ponger receiving, then an *actual* communication channel is
established, which we depict as follows:

![Synchronization](images/pingpong.svg)

In the diagram, the most important rule is the **synchronization rule**:

> for a given channel, a directed arrow is
> systematically drawned that connects all the sender processes to all the receiver ones.

This will allow to depict *competition* between senders and receivers on the same channel, a potentially
 very concurrent situation!


## Misc... (put these somewhere ?)

Q> ## What? Side-effects?
Q> Clojurians promote side-effect-free code using higher-order functions,
Q> immutable (GC'ed) datastructures and so on (think *transducers* ...) *as long as this makes sense* !
Q> Concurrency is (unlike parallel computing) pretty much about side-effects: creating processes/threads,
Q> sending messages, waiting/blocking, etc. Hence, *core.async* is no silver-bullet and most of its
Q> primitive involve one form or another of side effects. We will see, though, that higher-level
Q> and apparently side-effect-free constructions can be build *atop* the *core.async* primitives,
Q>  for example based on *dataflow* architectures.


